{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3046cafe",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:15.659772Z",
     "iopub.status.busy": "2022-08-27T06:55:15.659259Z",
     "iopub.status.idle": "2022-08-27T06:55:15.675150Z",
     "shell.execute_reply": "2022-08-27T06:55:15.673859Z"
    },
    "papermill": {
     "duration": 0.025933,
     "end_time": "2022-08-27T06:55:15.678057",
     "exception": false,
     "start_time": "2022-08-27T06:55:15.652124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4bb85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:15.688522Z",
     "iopub.status.busy": "2022-08-27T06:55:15.688080Z",
     "iopub.status.idle": "2022-08-27T06:55:23.519534Z",
     "shell.execute_reply": "2022-08-27T06:55:23.518091Z"
    },
    "papermill": {
     "duration": 7.841797,
     "end_time": "2022-08-27T06:55:23.524212",
     "exception": false,
     "start_time": "2022-08-27T06:55:15.682415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5499c54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.539994Z",
     "iopub.status.busy": "2022-08-27T06:55:23.537732Z",
     "iopub.status.idle": "2022-08-27T06:55:23.545361Z",
     "shell.execute_reply": "2022-08-27T06:55:23.544057Z"
    },
    "papermill": {
     "duration": 0.018818,
     "end_time": "2022-08-27T06:55:23.549362",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.530544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#有向無環圖(Directed Acyclic Graphs)\n",
    "#Inception神經網路由一堆Inception模組(module)組成\n",
    "#基本形式的Inception模組有3、4個分支，從1*1卷積開始，然後是3*3卷積，最後是結果特徵(張量)的串接，這樣設計有助於神經網路分別學習資料的channel特徵和空間特徵\n",
    "#複雜的Inception模組版本則涉及池化(pooling)的操作，或使用不同的空間卷積大小，以及沒有空間卷積的分支(僅1*1卷積:將輸入張量的channel資訊混在一起計算成特徵圖，不會混合到空間，也稱\"逐點卷積\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14fe8cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.563240Z",
     "iopub.status.busy": "2022-08-27T06:55:23.562550Z",
     "iopub.status.idle": "2022-08-27T06:55:23.781426Z",
     "shell.execute_reply": "2022-08-27T06:55:23.780162Z"
    },
    "papermill": {
     "duration": 0.232991,
     "end_time": "2022-08-27T06:55:23.786757",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.553766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28, 256)\n",
      "(1000, 14, 14, 64)\n",
      "(1000, 28, 28, 128)\n",
      "(1000, 14, 14, 128)\n",
      "(1000, 14, 14, 256)\n",
      "(1000, 14, 14, 128)\n",
      "(1000, 28, 28, 128)\n",
      "(1000, 28, 28, 128)\n",
      "(1000, 14, 14, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 06:55:23.646970: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "x = Input(batch_shape=(1000, 28, 28, 256)) #定義4D向量\n",
    "print(x.shape) #shape=(1000,28,28,256)\n",
    "\n",
    "#======================================================================================================#\n",
    "branch_a = layers.Conv2D(64, 1, activation='relu', strides=2)(x) #進行1/2採樣\n",
    "print(branch_a.shape) #shape=(1000,14,14,64)\n",
    "\n",
    "#======================================================================================================#\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x) #未進行採樣\n",
    "print(branch_b.shape) #shape=(1000,28,28,128)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_b) #進行1/2採樣\n",
    "print(branch_b.shape) #shape=(1000,14,14,128)\n",
    "\n",
    "#======================================================================================================#\n",
    "branch_c = layers.AveragePooling2D(3, strides=2, padding='same')(x) #採樣發生在平均池化層中\n",
    "print(branch_c.shape) #shape=(1000,14,14,256)\n",
    "\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu', padding='same')(branch_c)\n",
    "print(branch_c.shape) #shape=(1000,14,14,128)\n",
    "\n",
    "#======================================================================================================#\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "print(branch_d.shape) #shape=(1000,28,28,128)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 3 , activation='relu', padding='same')(branch_d)\n",
    "print(branch_d.shape) #shape=(1000,28,28,128)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2, padding='same')(branch_d) #進行1/2採樣\n",
    "print(branch_d.shape) #shape=(1000,14,14,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc9ee5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.797021Z",
     "iopub.status.busy": "2022-08-27T06:55:23.796528Z",
     "iopub.status.idle": "2022-08-27T06:55:23.812651Z",
     "shell.execute_reply": "2022-08-27T06:55:23.810912Z"
    },
    "papermill": {
     "duration": 0.024266,
     "end_time": "2022-08-27T06:55:23.815400",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.791134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 14, 14, 448)\n"
     ]
    }
   ],
   "source": [
    "#串接分支輸出以取得模組輸出\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71862a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.826056Z",
     "iopub.status.busy": "2022-08-27T06:55:23.824679Z",
     "iopub.status.idle": "2022-08-27T06:55:23.832559Z",
     "shell.execute_reply": "2022-08-27T06:55:23.831282Z"
    },
    "papermill": {
     "duration": 0.016292,
     "end_time": "2022-08-27T06:55:23.835665",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.819373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#每個分支皆有一個以相同步長(strides=2)進行採樣的層，這是為了保持所有分支輸出張量大小相同所必需的設定，以便最後可以串接每個分支的結果，但各分支的filters值不一定相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3972bc93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.845869Z",
     "iopub.status.busy": "2022-08-27T06:55:23.845418Z",
     "iopub.status.idle": "2022-08-27T06:55:23.850526Z",
     "shell.execute_reply": "2022-08-27T06:55:23.849278Z"
    },
    "papermill": {
     "duration": 0.013352,
     "end_time": "2022-08-27T06:55:23.852993",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.839641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Xception = extreme Inception(極端的Inception)\n",
    "#它採用將channel特徵和空間特徵的學習分離成邏輯極值的概念，並用深度可分離卷積層替換Inception模組\n",
    "#該卷積層由深度卷積組成(將輸入依channel切割，並個別處理空間卷積)，串接空間卷積的結果後進行逐點卷積(1*1卷積)\n",
    "#其中空間特徵、channel特徵明確，有效地完全分離，因為能更有效地使用模型參數，因此在大型資料集上取得更好的執行性能與準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb6e789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.863270Z",
     "iopub.status.busy": "2022-08-27T06:55:23.862415Z",
     "iopub.status.idle": "2022-08-27T06:55:23.867801Z",
     "shell.execute_reply": "2022-08-27T06:55:23.866966Z"
    },
    "papermill": {
     "duration": 0.013358,
     "end_time": "2022-08-27T06:55:23.870186",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.856828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#殘差連接(Residual connections)\n",
    "#神經網路架構中常見的圖形結構神經網路元件，包括剛剛提到的Xception\n",
    "#解決了大規模(多層)深度學習模型的兩個常見問題: 梯度消失、轉換瓶頸\n",
    "#殘差連接主要將上游層的輸出作為下游層的輸入，進而有效地在序列式神經網路中建立捷徑\n",
    "#將較早的啟動函數輸出張量與後面的啟動函數輸出張量相加，若張量的shape大小相同，則可直接相加；若大小不同，則可使用線性轉換將較早的張量shape調整為下游張量的shape\n",
    "#線性轉換: T:矩陣，可加性: T(u + v) = T(u) + T(v)，齊次性: aT(u) = T(au)[a為任意純量]\n",
    "#神經網路中啟動函數結果(張量)也可透過線性轉換改變其shape大小，ex:使用沒有啟動函數的Dense層，卷積特徵圖則是使用沒有啟動函數的1*1卷積"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27f24586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.880797Z",
     "iopub.status.busy": "2022-08-27T06:55:23.879881Z",
     "iopub.status.idle": "2022-08-27T06:55:23.918866Z",
     "shell.execute_reply": "2022-08-27T06:55:23.917488Z"
    },
    "papermill": {
     "duration": 0.048074,
     "end_time": "2022-08-27T06:55:23.922172",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.874098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "#啟動函數輸出張量shape大小相同的殘差連接\n",
    "x = Input(batch_shape=(1000, 32, 32, 128)) #定義4D張量\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) #y.shape=(1000,32,32,128)\n",
    "z = layers.Conv2D(128, 3, activation='relu', padding='same')(y) #z.shape=(1000,32,32,128)\n",
    "op = layers.add([z, x]) #x與z的shape皆等於(1000,32,32,128)，可直接連接\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be53003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-27T06:55:23.932334Z",
     "iopub.status.busy": "2022-08-27T06:55:23.931887Z",
     "iopub.status.idle": "2022-08-27T06:55:23.986939Z",
     "shell.execute_reply": "2022-08-27T06:55:23.985055Z"
    },
    "papermill": {
     "duration": 0.064749,
     "end_time": "2022-08-27T06:55:23.991100",
     "exception": false,
     "start_time": "2022-08-27T06:55:23.926351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 128)\n",
      "(1000, 16, 16, 128)\n",
      "(1000, 16, 16, 128)\n",
      "(1000, 16, 16, 128)\n"
     ]
    }
   ],
   "source": [
    "#啟動函數輸出張量shape大小不同時，透過線性轉換，改變張量的shape，使其大小相同，再進行殘差連接\n",
    "x = Input(batch_shape=(1000, 32, 32, 256)) #建立4D輸入張量\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "z = layers.Conv2D(128, 3 ,activation='relu', padding='same')(y)\n",
    "print(z.shape) #shape=(1000,32,32,128)\n",
    "\n",
    "t = layers.MaxPooling2D(2, strides=2)(z) #步長=2代表進行1/2的縮小採樣，張量大小減半(特徵圖的長寬)\n",
    "print(t.shape) #shape=(1000,16,16,128)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x) #線性轉換: 對張量x使用步長=2的1*1卷積，進行1/2縮小採樣，並將channel降低成與張量t相同的128\n",
    "print(residual.shape) #經過線性轉換後的殘差張量shape=(1000,16,16,128)\n",
    "\n",
    "op = layers.add([t, residual]) #將殘差張量residual加回輸出特徵張量t\n",
    "print(op.shape) #shape=(1000,16,16,128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0a6 (main, Mar  7 2022, 16:46:19) [MSC v.1929 64 bit (AMD64)]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.34595,
   "end_time": "2022-08-27T06:55:27.572967",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-27T06:55:03.227017",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
