{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-27T07:47:11.925090Z","iopub.status.busy":"2022-08-27T07:47:11.924513Z","iopub.status.idle":"2022-08-27T07:47:11.933666Z","shell.execute_reply":"2022-08-27T07:47:11.932177Z","shell.execute_reply.started":"2022-08-27T07:47:11.925048Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:47:11.936977Z","iopub.status.busy":"2022-08-27T07:47:11.936456Z","iopub.status.idle":"2022-08-27T07:47:11.957193Z","shell.execute_reply":"2022-08-27T07:47:11.955897Z","shell.execute_reply.started":"2022-08-27T07:47:11.936928Z"},"trusted":true},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers, models, Input"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:47:11.960110Z","iopub.status.busy":"2022-08-27T07:47:11.958876Z","iopub.status.idle":"2022-08-27T07:47:11.968657Z","shell.execute_reply":"2022-08-27T07:47:11.967479Z","shell.execute_reply.started":"2022-08-27T07:47:11.960070Z"},"trusted":true},"outputs":[],"source":["#層的權重共享\n","#函數式API其中一個重要特性是能重複使用層物件\n","#有個評估兩個句子語義相似與否的模型，此模型有兩個輸入(兩個要比較的句子)，輸出0~1之間的分數，其中0表示不相關，1則表示完全相同或僅是重新排列的句子\n","#此模型在對話系統中，可去除重複的語句\n","#此案例中兩個輸入句子是可互換的，因為語義相似性是對稱關係:A到B的相似性與B到A的相似性相同，因此我們可以使用單個LSTM層處理這兩個句子\n","#這個LSTM層的表示法(權重)是基於兩個輸入同時學習，也就是孿生LSTM(Siamese LSTM)或共享LSTM(shared LSTM)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:47:35.798047Z","iopub.status.busy":"2022-08-27T07:47:35.797301Z","iopub.status.idle":"2022-08-27T07:47:36.254702Z","shell.execute_reply":"2022-08-27T07:47:36.253421Z","shell.execute_reply.started":"2022-08-27T07:47:35.798001Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(None, None, 128)\n","(None, 32)\n","(None, None, 128)\n","(None, 32)\n"]}],"source":["lstm = layers.LSTM(32) #建立一個神經元32個的LSTM物件\n","\n","left_input = Input(shape=(None, 128)) #建立模型的左輸入分支:可變長度的向量，大小為128\n","print(left_input.shape) #左分支的輸入張量shape=(?,?,128)\n","left_output = lstm(left_input) #傳入LSTM物件\n","print(left_output.shape) #左分支的輸出張量shape=(?,32)\n","\n","right_input = Input(shape=(None, 128)) #建立模型的右輸入分支:可變長度的向量，大小為128\n","print(right_input.shape) #右分支的輸入張量shape=(?,?,128)\n","right_output = lstm(right_input) #傳入\"同一個\"LSTM物件\n","print(right_output.shape) #右分支的輸出張量shape=(?,32)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:49:15.047129Z","iopub.status.busy":"2022-08-27T07:49:15.046698Z","iopub.status.idle":"2022-08-27T07:49:15.061158Z","shell.execute_reply":"2022-08-27T07:49:15.059951Z","shell.execute_reply.started":"2022-08-27T07:49:15.047093Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(None, 64)\n"]}],"source":["#將向量串接\n","merged = layers.concatenate([left_output, right_output], axis=-1)\n","print(merged.shape) #串接後向量shape=(?,32+32=64)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:50:43.511773Z","iopub.status.busy":"2022-08-27T07:50:43.511356Z","iopub.status.idle":"2022-08-27T07:50:43.527380Z","shell.execute_reply":"2022-08-27T07:50:43.526042Z","shell.execute_reply.started":"2022-08-27T07:50:43.511731Z"},"trusted":true},"outputs":[],"source":["#將串接後的向量傳入最後的輸出層Dense進行分類\n","predictions = layers.Dense(1, activation='sigmoid')(merged)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:52:18.305613Z","iopub.status.busy":"2022-08-27T07:52:18.305213Z","iopub.status.idle":"2022-08-27T07:52:18.315218Z","shell.execute_reply":"2022-08-27T07:52:18.314215Z","shell.execute_reply.started":"2022-08-27T07:52:18.305581Z"},"trusted":true},"outputs":[],"source":["#用輸入向量(2個)與輸出向量建立Model物件\n","model = models.Model([left_input, right_input], predictions)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T07:52:38.927741Z","iopub.status.busy":"2022-08-27T07:52:38.927375Z","iopub.status.idle":"2022-08-27T07:52:38.935648Z","shell.execute_reply":"2022-08-27T07:52:38.934750Z","shell.execute_reply.started":"2022-08-27T07:52:38.927711Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, None, 128)]  0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, None, 128)]  0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   (None, 32)           20608       input_3[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 64)           0           lstm_1[0][0]                     \n","                                                                 lstm_1[1][0]                     \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            65          concatenate[0][0]                \n","==================================================================================================\n","Total params: 20,673\n","Trainable params: 20,673\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#訓練模型\n","model.fit([left_data, right_data], labels)\n","#當訓練這樣的模型時，LSTM層的權重將同時依據兩個輸入進行更新"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T08:06:03.135764Z","iopub.status.busy":"2022-08-27T08:06:03.134980Z","iopub.status.idle":"2022-08-27T08:06:03.140991Z","shell.execute_reply":"2022-08-27T08:06:03.139893Z","shell.execute_reply.started":"2022-08-27T08:06:03.135721Z"},"trusted":true},"outputs":[],"source":["#將模型作為層\n","#函數式API中最為重要的功能是，能將模型A放到另個模型B中來做使用，Sequential和Model類別都能使用\n","#用輸入張量(x)直接呼叫模型物件(視為一個層)，並取得輸出張量(y)\n","#y = model(x)\n","#y1, y2 = model([x1, x2])\n","#呼叫一個物件時，無論是\"層物件\"或是\"模型物件\"，將會重複使用物件現已學習到的表示法(權重)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T08:16:58.810355Z","iopub.status.busy":"2022-08-27T08:16:58.808719Z","iopub.status.idle":"2022-08-27T08:17:00.994503Z","shell.execute_reply":"2022-08-27T08:17:00.993059Z","shell.execute_reply.started":"2022-08-27T08:16:58.810300Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(None, 8, 8, 2048)\n","(None, 8, 8, 2048)\n"]}],"source":["#一個使用雙攝影鏡頭影像作為輸入的視覺模型，即設置兩個並行(相距幾公分)的攝影鏡頭\n","#此模型可以感知影像深度，延伸許多應用，ex:3D人臉辨識\n","#使用同一個層對左、右鏡頭一起進行萃取其視覺特徵，從而共享相同的表示法(權重)，稱為孿生(Siamese)視覺模型(共享卷積基礎)\n","from tensorflow.keras.applications import Xception\n","\n","xception_base = Xception(weights=None, include_top=False) #使用Xception神經網路的卷積基底(不包含最上層分類器)進行影像特徵萃取\n","\n","#建立左、右輸入張量(左、右鏡頭影像)，其shape=(250,250,3)，即為250*250的彩色影像\n","left_input = Input(shape=(250, 250, 3))\n","right_input = Input(shape=(250, 250, 3))\n","\n","#呼叫相同的視覺模型兩次，將左、右影像張量傳入Xception神經網路物件\n","left_features = xception_base(left_input)\n","right_features = xception_base(right_input)\n","\n","print(left_features.shape)\n","print(right_features.shape)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T08:18:24.080285Z","iopub.status.busy":"2022-08-27T08:18:24.079470Z","iopub.status.idle":"2022-08-27T08:18:24.091353Z","shell.execute_reply":"2022-08-27T08:18:24.090234Z","shell.execute_reply.started":"2022-08-27T08:18:24.080243Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(None, 8, 8, 4096)\n"]}],"source":["#串接左右影像特徵張量\n","merged_features = layers.concatenate([left_features, right_features], axis=-1)\n","print(merged_features.shape)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0a6 (main, Mar  7 2022, 16:46:19) [MSC v.1929 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"}}},"nbformat":4,"nbformat_minor":4}
