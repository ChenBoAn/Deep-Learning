{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-27T12:27:08.543687Z","iopub.status.busy":"2022-08-27T12:27:08.543231Z","iopub.status.idle":"2022-08-27T12:27:08.578459Z","shell.execute_reply":"2022-08-27T12:27:08.577438Z","shell.execute_reply.started":"2022-08-27T12:27:08.543594Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T14:51:08.576017Z","iopub.status.busy":"2022-08-27T14:51:08.575672Z","iopub.status.idle":"2022-08-27T14:51:08.581489Z","shell.execute_reply":"2022-08-27T14:51:08.580037Z","shell.execute_reply.started":"2022-08-27T14:51:08.575976Z"},"trusted":true},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import callbacks, models"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T13:06:59.255899Z","iopub.status.busy":"2022-08-27T13:06:59.255616Z","iopub.status.idle":"2022-08-27T13:06:59.260206Z","shell.execute_reply":"2022-08-27T13:06:59.259135Z","shell.execute_reply.started":"2022-08-27T13:06:59.255876Z"},"trusted":true},"outputs":[],"source":["#回呼(callbacks): 呼叫fit()方法時傳遞給模型的一個物件(一個執行特定方法的物件)，在訓練期間由模型在各節點呼叫\n","#可在發現測量驗證損失不再改善時即停止訓練、儲存模型、載入不同的權重、更改模型的狀態\n","#可使用回乎的範例:\n","#1.模型檢查點(model checkpoint): 訓練時間保存模型在不同時間點的權重\n","#2.早期停止(early stopping): 當驗證損失不再改善時中斷訓練，並自動保存訓練時間獲得的最佳模型\n","#3.在訓練期間動態調整某些參數的值，ex:優化器的學習效率\n","#4.在訓練期間記錄訓練和驗證指標，或在模型更新時視覺化模型已學習到的表示法(權重)，ex:Keras透過回呼處理進度條圖"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T13:09:04.474066Z","iopub.status.busy":"2022-08-27T13:09:04.473731Z","iopub.status.idle":"2022-08-27T13:09:04.478759Z","shell.execute_reply":"2022-08-27T13:09:04.477622Z","shell.execute_reply.started":"2022-08-27T13:09:04.474042Z"},"trusted":true},"outputs":[],"source":["#keras.callbacls.LearningRateScheduler: 自訂函數，動態調整學習率，ex:10個epoch前，學習率不變；10之後的每一個epoch學習率變之前的一半\n","#keras.callbacks.CSVLogger: 保存訓練的loss和accuracy等資訊到csv檔\n","#keras.callbacks.TerminateOnNaN：loss變成NaN時停止，通常發生在學習率過大開始發散時"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T13:11:19.106434Z","iopub.status.busy":"2022-08-27T13:11:19.106112Z","iopub.status.idle":"2022-08-27T13:11:19.111116Z","shell.execute_reply":"2022-08-27T13:11:19.110009Z","shell.execute_reply.started":"2022-08-27T13:11:19.106408Z"},"trusted":true},"outputs":[],"source":["#早期停止EarlyStopping 和 模型檢查點ModelCheckpoint 回呼\n","#當監控的指標(ex:驗證損失)在一定數量的訓練週期(次數)停止改善，即可使用EarlyStopping回呼來中斷訓練\n","#結合ModelCheckPoint回呼使用，在訓練期間不斷儲存模型(可選擇保存最佳的模型版本)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-08-27T13:24:57.155718Z","iopub.status.busy":"2022-08-27T13:24:57.154968Z","iopub.status.idle":"2022-08-27T13:25:00.055702Z","shell.execute_reply":"2022-08-27T13:25:00.052079Z","shell.execute_reply.started":"2022-08-27T13:24:57.155690Z"},"trusted":true},"outputs":[],"source":["#用串列打包回呼，傳遞給模型\n","                #回呼1\n","callbacks_list = [callbacks.EarlyStopping(monitor='val_acc', #監控模型的驗證精準度\n","                                               patience=1), #當監控的指標超過1個epochs未改善則停止訓練\n","                #回呼2\n","                 callbacks.ModelCheckpoint(filepath='my_model.h5', #每個epochs結束後儲存模型\n","                                          monitor='val_loss', #當val_loss取得改善時，回呼才會儲存模型\n","                                          save_best_only=True)]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer='rmsprop',\n","             loss='binary_crossentropy',\n","             metrics=['acc'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(x, y,\n","         validation_data=(x_val, y_val),\n","         epochs=10,\n","         batch_size=32,\n","         callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#ReduceLROnPlateau回呼:當驗證損失停止改善時(進入高原期plateau)，可使用此回呼降低學習率\n","#在損失停滯(loss plateau)的情況下，降低或提高學習率式訓練期間擺脫局部最小值的有效策略"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["callbacks_list = [callbacks.ReduceLROnPlateau(monitor='val_loss', #監控模型的驗證損失\n","                                             factor=0.1, #模型呼叫回呼時，將學習率*0.1\n","                                             patience=10)] #當監控的指標超過10個epochs未改善則呼叫回呼"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.fit(x, y,\n","         validation=(x_val, y_val),\n","         epochs=10,\n","         batch_size=32,\n","         callbacks=callbacks_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#撰寫自己的回呼: 透過繼承keras.callbacks.Callback類別，編寫自己需要的method\n","#這些method在呼叫時都會使用logs參數，這是一個字典(dict)，包含上一批次量、訓練週期(次數)、訓練與驗證指標...\n","#回呼會存取以下屬性:\n","#self.model: 呼叫回呼的模型物件\n","#self.validation_data: 傳遞給fit作為驗證資料的數值\n","\n","#method需要明確的命名:\n","#on_epoch_begin:在每個訓練週期(次數)的開始時呼叫\n","#on_epoch_end:在每個訓練週期(次數)的結束時呼叫\n","#on_batch_begin:在處理每個批次量前呼叫\n","#on_batch_end:在處理每個批次量後呼叫\n","#on_train_begin:在訓練開始時呼叫\n","#on_train_end:在訓練結束時呼叫"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#此回呼在每個訓練週期(次數)結束時，以驗證資料集的第一個樣本，計算模型的每一層啟動函數結果，並儲存到磁碟中(以Numpy陣列形式)\n","class ActivationLogger(callbacks.Callback): #繼承Callback類別\n","    def set_model(self, model):\n","        self.model = model #訓練前由父模型呼叫，以設定哪個模型要使用回呼\n","        layers_outputs = [layer.output for layer in model.layers] #取得模型中每一層輸出\n","        self.activations_model = models.Model(model.input, layer_outputs) #透過輸入與每一層的輸出來建立每一層的Model物件\n","        \n","    def on_epoch_end(self, epoch, logs=None): #在每個訓練週期結束時呼叫\n","        if self.validation is None:\n","            raise RuntimeError('Requires validation_data')\n","        \n","        validation_sample = self.validation_data[0][0:1] #取得驗證集的第一個樣本\n","        activations = self.activation_model.predict(validation_sample) #將此樣本送入每一層Model物件，取得輸出結果(張量)\n","        #將結果張量儲存到磁碟中(.npz檔)\n","        f = open('activation_at_epoch_', str(epoch) + '.npz', 'w')\n","        np.savez(f, activations)\n","        f.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.3 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"},"vscode":{"interpreter":{"hash":"8e2fdfaba40b754b78c79fd14f3ea3f51484489fc81ab2e0ca96f8f821a6887f"}}},"nbformat":4,"nbformat_minor":4}
